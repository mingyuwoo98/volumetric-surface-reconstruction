{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangulation for sequence of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.image as image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image\n",
    "from Dino_Images import *\n",
    "from skimage import feature\n",
    "from skimage.feature import (corner_harris, corner_peaks, plot_matches, BRIEF, match_descriptors)\n",
    "from skimage.transform import warp, FundamentalMatrixTransform, rotate\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import ransac\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating F matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(dino_param_df):\n",
    "    \"\"\"\n",
    "    Read the text file to get the parmeters of interest: K, R, T\n",
    "    \"\"\"\n",
    "\n",
    "    param_dict = {}\n",
    "\n",
    "    for i in range(len(dino_param_df)):\n",
    "        row = dino_param_df.loc[i]\n",
    "        K = np.array(row.loc[1:9].tolist()).reshape(3,3)\n",
    "        R = np.array(row.loc[10:18].tolist()).reshape(3,3)\n",
    "        T = np.array(row.loc[19:].tolist()).reshape(3,1)\n",
    "\n",
    "        # param_dict[dino_param_df.loc[i][0]] = [K, R, T]\n",
    "        param_dict[i] = [K, R, T]\n",
    "    \n",
    "    return param_dict\n",
    "\n",
    "\n",
    "def get_cross_matrix(T):\n",
    "    \"\"\"\n",
    "    T_mat = [ 0  -a3 a2]\n",
    "            [ a3  0 -a1]\n",
    "            [-a2 a1  0 ]\n",
    "    \"\"\"\n",
    "    a1, a2, a3 = T\n",
    "\n",
    "    T_mat = np.zeros((3,3))\n",
    "    T_mat[0, 1] = -a3\n",
    "    T_mat[0, 2] = a2\n",
    "    T_mat[1, 0] = a3\n",
    "    T_mat[1, 2] = -a1\n",
    "    T_mat[2, 0] = -a2\n",
    "    T_mat[2, 1] = a1\n",
    "\n",
    "    return T_mat\n",
    "\n",
    "def get_F_matrix_sourishghosh(K1, R1, T1, K2, R2, T2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    P1 = K1 @ np.hstack([R1, T1])\n",
    "    P2 = K2 @ np.hstack([R2, T2])\n",
    "\n",
    "    # Calculate Pseudo-Inverse\n",
    "    P1_pI = np.linalg.pinv(P1)\n",
    "    \n",
    "    # Camera center of the first camera\n",
    "    C1 = np.linalg.solve(P1[:, :-1], -P1[:, -1])\n",
    "    \n",
    "    # Camera center in homogenous coordinates\n",
    "    C1 = np.hstack([C1, 1])\n",
    "    \n",
    "    # Epipole of C1 into second image\n",
    "    E2 = P2 @ C1\n",
    "\n",
    "    # Calculate F matrix\n",
    "    E2_mat = get_cross_matrix(E2)\n",
    "    F_mat = E2_mat @ P2 @ P1_pI\n",
    "\n",
    "    return F_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Matching Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_on_dino(imL, num_feature_points = None, dino_threshold = 0.4):\n",
    "    \"\"\"\n",
    "    bounding_box_size must be ODD number\n",
    "    \"\"\"\n",
    "\n",
    "    # SAMPLE RANDOM INDICES\n",
    "    h,w,_ = np.shape(imL)\n",
    "\n",
    "    mask_dino = np.where(np.sum(imL, axis = 2) > dino_threshold, 1, 0)\n",
    "    mask_dino = np.where(mask_dino == 1)\n",
    "\n",
    "    points = np.array([mask_dino[1], mask_dino[0]]).T\n",
    "    \n",
    "    if not num_feature_points:\n",
    "        return points\n",
    "    \n",
    "    idx = np.random.choice(np.arange(points.shape[0]), size = num_feature_points, replace = False)\n",
    "\n",
    "    x1 = points[idx]\n",
    "    \n",
    "    return x1\n",
    "\n",
    "\n",
    "def get_bound_box_intensities(im, point, bounding_box_size):\n",
    "    u, v_dec = int(point[0]), point[1]\n",
    "    v_ceil, v_floor = int(np.ceil(v_dec)), int(np.floor(v_dec))\n",
    "\n",
    "    i = bounding_box_size//2\n",
    "\n",
    "    im_cropped_list = []\n",
    "\n",
    "    for v in [v_ceil, v_floor]:\n",
    "        w_min, w_max = u - i, u + i\n",
    "        h_min, h_max = v - i, v + i\n",
    "\n",
    "        im_cropped_list.append(im[h_min:(h_max+1), w_min:(w_max+1), :])\n",
    "\n",
    "    return im_cropped_list[0], v_ceil, im_cropped_list[1], v_floor\n",
    "\n",
    "\n",
    "def loss_function_abs(image_point, image_point_2, imL_cropped, imR_cropped): # Depreciated\n",
    "\n",
    "    # Photoconsistency (?) + (Positional Consistency)\n",
    "    # Photoconsistency hovers around [0.1, 12]\n",
    "    # Positional Consistency hovers around [30, 600] (divide by 100 maybe?)\n",
    "    loss = 70*np.sum(np.abs(imL_cropped - imR_cropped)) + np.sum(np.linalg.norm(image_point - image_point_2))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_function_default(image_point, image_point_2, imL_cropped, imR_cropped):\n",
    "\n",
    "    # Photoconsistency (?) + (Positional Consistency)\n",
    "    photo_con_loss = np.sum(np.abs(imL_cropped - imR_cropped))\n",
    "    pos_loss = np.sum(np.abs(image_point[1] - image_point_2[1]))\n",
    "\n",
    "    loss = photo_con_loss + 3*pos_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_right_epipolar_line(imR, x1, F):\n",
    "    \"\"\"\n",
    "    x1 are image points\n",
    "    \"\"\"\n",
    "\n",
    "    def predict_y(l, x): \n",
    "        a = -np.divide(l[:,0], l[:,1]) \n",
    "        b = -np.divide(l[:,2], l[:,1]) \n",
    "\n",
    "        return np.multiply(a[:,None], x) + b[:,None] \n",
    "\n",
    "    x1_homo = np.append(x1, np.ones(len(x1))[:,None], axis = 1) \n",
    "    \n",
    "    l2 = x1_homo @ F.T\n",
    "\n",
    "    u = np.repeat(np.array([0, imR.shape[1]])[None,:], len(x1), axis=0) \n",
    "\n",
    "    v = predict_y(l2, u)\n",
    "\n",
    "    return u, v, l2\n",
    "\n",
    "\n",
    "def get_left_epipolar_line(imL, x2, F):\n",
    "    \"\"\"\n",
    "    x1 are image points\n",
    "    \"\"\"\n",
    "\n",
    "    def predict_y(l, x): \n",
    "        a = -np.divide(l[:,0], l[:,1]) \n",
    "        b = -np.divide(l[:,2], l[:,1]) \n",
    "\n",
    "        return np.multiply(a[:,None], x) + b[:,None] \n",
    "    \n",
    "    x2_homo = np.append(x2, np.ones(len(x2))[:,None], axis = 1) \n",
    "    \n",
    "    l1 = x2_homo @ F\n",
    "\n",
    "    u = np.repeat(np.array([0, imL.shape[1]])[None,:], len(x2), axis=0) \n",
    "\n",
    "    v = predict_y(l1, u)\n",
    "\n",
    "    return u, v, l1\n",
    "\n",
    "def get_right_image_point(imL, imR, image_point, x2_on_eline, \n",
    "                               bounding_box_size, loss_function = loss_function_default):\n",
    "    \n",
    "    final_image_point_2_list, final_loss_list = [], []\n",
    "    \n",
    "    # For giving image_point and bounding_box_size return cropped array\n",
    "    imL_cropped, _, _, _ = get_bound_box_intensities(imL, image_point, bounding_box_size)\n",
    "\n",
    "    for i in range(len(x2_on_eline)):\n",
    "        # Testing if current point on epipolar line in image 2 works\n",
    "        image_point_2 = x2_on_eline[i, :]\n",
    "        \n",
    "        # Return the (bounding_box_size x bounding_box_size x 3)\n",
    "        imR_cropped_ceil, v_ceil, imR_cropped_floor, v_floor = \\\n",
    "        get_bound_box_intensities(imR, image_point_2, bounding_box_size)\n",
    "\n",
    "        # Custom loss functino\n",
    "        image_point_2_list= [np.array([image_point_2[0], v_ceil]), np.array([image_point_2[0], v_floor])]\n",
    "        \n",
    "        # bb_int_L[0] = bb_int_L[1] since the image_point are all ints to begin with\n",
    "        loss_list = [loss_function(image_point, image_point_2_list[0], imL_cropped, imR_cropped_ceil), \\\n",
    "                        loss_function(image_point, image_point_2_list[1], imL_cropped, imR_cropped_floor)]\n",
    "\n",
    "        loss_arg = np.argmin(loss_list)\n",
    "        \n",
    "        image_point_2 = image_point_2_list[loss_arg]\n",
    "        loss = loss_list[loss_arg]\n",
    "        \n",
    "        final_image_point_2_list.append(image_point_2)\n",
    "        final_loss_list.append(loss)\n",
    "    \n",
    "    final_R_point = final_image_point_2_list[np.argmin(final_loss_list)]\n",
    "\n",
    "    return final_R_point\n",
    "\n",
    "def point_and_line(point_index, x1, w, h, u, l2_list):\n",
    "    '''\n",
    "    Takes a index in x1 and returns the point along with its corresponding epipolar line formatted nicely as input\n",
    "    for the matching function \n",
    "    '''\n",
    "    image_point = np.array([x1[point_index, 0], x1[point_index, 1]])\n",
    "\n",
    "    # l2 corresponding with the image_point\n",
    "    l2 = l2_list[point_index,:]\n",
    "\n",
    "    # Generate all points on epipolar line projected from first image plane\n",
    "    a = -l2[0]/l2[1]\n",
    "    b = -l2[2]/l2[1]\n",
    "\n",
    "    # Produce all the points on the epipolar line\n",
    "#     u2 = np.linspace(0, w, num = 5*w)\n",
    "#    v2 = a*u+b\n",
    "\n",
    "    v_top = 0\n",
    "    u_top = -b/a\n",
    "    \n",
    "    v_bot = h\n",
    "    u_bot = (h-b)/a\n",
    "    \n",
    "#     delta_v = v_bot - v_top\n",
    "#     delta_u = u_bot - u_top\n",
    "    \n",
    "    u2 = np.linspace(u_top, u_bot, min([w,h]))\n",
    "    v2 = np.linspace(v_top, v_bot, min([w,h]))\n",
    "\n",
    "    # Extract all the points on the epipolar line that are within the image (and not restricted by the bounding_box_size)\n",
    "    idx = np.where((v2 > bounding_box_size)&(v2 < h-bounding_box_size)& \\\n",
    "    (u2 > bounding_box_size)&(u2 < w-bounding_box_size))[0]\n",
    "\n",
    "    u2 = u2[idx]\n",
    "    v2 = v2[idx]\n",
    "    \n",
    "    # Stack the individual coordinates to make (n x 2) vector\n",
    "    x2_on_eline = np.vstack((u2, v2)).T\n",
    "    x2_on_eline = np.rint(x2_on_eline).astype(int)\n",
    "    image_point = np.rint(image_point).astype(int)\n",
    "    print(x2_on_eline.shape)\n",
    "    return image_point, x2_on_eline\n",
    "\n",
    "def get_right_image_point_cv(imL, imR, impts, x2_on_eline = None, shift = None,\n",
    "                               bbr = 5, epsilon = 0, method = cv2.TM_CCOEFF_NORMED,\n",
    "                               show_img = False, matched_start = None, matched_end = None, delta = 0):\n",
    "    # delta = 0.00000000001 DEFAULT FOR dinoRing and dinoSparseRing\n",
    "    h, w = bbr*2+1, bbr*2+1\n",
    "    x, y = impts\n",
    "    img = imR.copy()\n",
    "    img_ref = imL.copy()\n",
    "    if not shift: # Define horizontal shift\n",
    "        shift = (-bbr, bbr)\n",
    "        \n",
    "    # Get template from imL\n",
    "    imL_padded = np.pad(imL, [(bbr, bbr), (bbr, bbr), (0, 0)], mode='constant')\n",
    "    template = imL_padded[y:y+h, x:x+w, :]\n",
    "\n",
    "    result = cv2.matchTemplate(img, template, method)\n",
    "    result_padded = np.pad(result, [(bbr, bbr), (bbr, bbr)], mode='constant')\n",
    "\n",
    "    # return location with max score along x2 lines\n",
    "    shift_template = np.repeat(np.array([0, 1])[None, :], x2_on_eline.shape[0], axis = 0)\n",
    "    shift_diff = shift[1] - shift[0] + 1\n",
    "    result_eline = np.zeros((shift_diff, x2_on_eline.shape[0]))\n",
    "\n",
    "    # used to compute the projection of the point to be matched along the line from the\n",
    "    # match of the start to the match of the end in the right image\n",
    "    if not(matched_start is None and matched_end is None):\n",
    "        line = matched_start - matched_end\n",
    "        l = 1 / np.sum((line)**2) * (line)\n",
    "    \n",
    "    for s in range(shift[0], shift[1]):\n",
    "        x2_eline_shifted = x2_on_eline + shift_template * s\n",
    "        x2_eline_shifted = np.where(x2_eline_shifted < 0, 0, x2_eline_shifted)\n",
    "        x2_eline_shifted_y = np.where(x2_eline_shifted[:,1] >= img.shape[0], img.shape[0] - 1, x2_eline_shifted[:,1])\n",
    "        x2_eline_shifted_x = np.where(x2_eline_shifted[:,0] >= img.shape[1], img.shape[1] - 1, x2_eline_shifted[:,0])\n",
    "        result_eline_shifted = result_padded[(x2_eline_shifted_y, x2_eline_shifted_x)]\n",
    "        # Add penality on shifting\n",
    "        result_eline_shifted -= epsilon * result_eline_shifted * abs(2 * s) / shift_diff \n",
    "        \n",
    "        # Add penality on dist from line between matched_start and matched_end to enforce order\n",
    "        if not(matched_start is None and matched_end is None):\n",
    "            \n",
    "            # reshaping the points on the epipolar line so we can calculate all the projections at once\n",
    "            epi_line = np.array([x2_eline_shifted_y, x2_eline_shifted_x])\n",
    "            \n",
    "            # create copies of the sampled line so we can take multiple dot products simultaneously\n",
    "            line_reshaped = np.tile(line, epi_line.shape[1]).reshape((epi_line.shape[1], epi_line.shape[0]))\n",
    "            \n",
    "            a, b = epi_line.shape\n",
    "            matched_start_reshaped = np.tile(matched_start, epi_line.shape[1]).reshape(epi_line.shape)\n",
    "            \n",
    "            dot_product = np.dot(epi_line.transpose(), line_reshaped.transpose())\n",
    "            scale = np.sum(dot_product, axis=1)\n",
    "            projections = matched_start_reshaped + np.multiply(scale, np.tile(l, epi_line.shape[1]).reshape((a,b)))\n",
    "            \n",
    "            diff = projections - epi_line\n",
    "            penalty = np.sum(np.square(diff),axis=0)\n",
    "\n",
    "            result_eline_shifted -= delta * penalty \n",
    "        \n",
    "        result_eline[s - shift[0], :] = result_eline_shifted\n",
    "\n",
    "    score = result_eline.max()\n",
    "    max_idx = np.where(result_eline == score)\n",
    "    location_eline = x2_on_eline + shift_template * (max_idx[0][0] + shift[0])\n",
    "    location = location_eline[max_idx[1][0],:]\n",
    "    \n",
    "    if show_img:\n",
    "        bottom_right = (location[0] + w, location[1] + h)   \n",
    "        impts_bottom_right = (x + w, y + h)   \n",
    "        cv2.rectangle(img, location, bottom_right, 255, 5)\n",
    "        cv2.rectangle(img_ref, impts, impts_bottom_right, 255, 5)\n",
    "\n",
    "        plt.figure(0,figsize = (10, 4))\n",
    "        ax81 = plt.subplot(121)\n",
    "        plt.imshow(img_ref)\n",
    "        ax82 = plt.subplot(122)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "    return location, score\n",
    "\n",
    "def get_match_points_linspace(imL, imR, x1, F, bounding_box_size, epsilon, threshold = 0.8, delta = 0.00000000001):\n",
    "\n",
    "    # Define some common variables:\n",
    "        # after rotating img:(480 x 640 x 3)\n",
    "    h,w,c = np.shape(imL)\n",
    "    u = np.linspace(0, w, num = 5*w)\n",
    "\n",
    "    u2_list, v2_list, l2_list = get_right_epipolar_line(imR, x1, F)\n",
    "\n",
    "    \n",
    "    start, start_line = point_and_line(0, x1, w, h, u, l2_list)\n",
    "    end, end_line = point_and_line(-1, x1, w, h, u, l2_list)\n",
    "    \n",
    "    matched_start, score_start = get_right_image_point_cv(imL, imR, start, start_line, shift = (-20, 20), bbr = bounding_box_size, epsilon = epsilon, show_img = False)\n",
    "    matched_end, score_end = get_right_image_point_cv(imL, imR, end, end_line, shift = (-20, 20), bbr = bounding_box_size, epsilon = epsilon, show_img = False)\n",
    "\n",
    "    x2_list = []\n",
    "    for i in range(len(x1)):\n",
    "        image_point, x2_on_eline = point_and_line(i, x1, w, h, u, l2_list)\n",
    "\n",
    "    #         # Return final_R_point on the right image that is closest to image_point on the left image \n",
    "        final_R_point, score = get_right_image_point_cv(imL, imR, image_point, x2_on_eline, shift = (-20, 20), \n",
    "                                                   bbr = bounding_box_size, epsilon = epsilon, matched_start = matched_start, matched_end = matched_end, delta=delta)\n",
    "\n",
    "        x2_list.append(final_R_point if score > threshold else np.array([-1,-1])) \n",
    "\n",
    "    x2 = np.array(x2_list)\n",
    "    \n",
    "    u1_list, v1_list, _ = get_left_epipolar_line(imL, x2, F)\n",
    "\n",
    "    return x2, u1_list, v1_list, u2_list, v2_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulation(x1, x2, P1, P2):\n",
    "    A = np.apply_along_axis(get_matrix_A, 1, np.hstack([x1, x2]), P1, P2)\n",
    "\n",
    "    # least squares for solving linear system A_{0:2} X_{0:2} = - A_3 \n",
    "    A_02 = A[:, :, 0:3]       # the first 3 columns of 4x4 matrix A\n",
    "    A_3  = A[:, :, 3]       # the last column on 4x4 matrix A\n",
    "\n",
    "    X = least_squares_est(A_02, -A_3)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def get_matrix_A(pair_points, P_1, P_2):\n",
    "    # X = np.append([n_ptsL, n_ptsR])\n",
    "    A_row_1 = P_1[0, :] - pair_points[0]*P_1[2, :]\n",
    "    A_row_2 = P_1[1, :] - pair_points[1]*P_1[2, :]\n",
    "    A_row_3 = P_2[0, :] - pair_points[2]*P_2[2, :]\n",
    "    A_row_4 = P_2[1, :] - pair_points[3]*P_2[2, :]\n",
    "    \n",
    "    A = np.vstack([A_row_1, A_row_2, A_row_3, A_row_4])\n",
    "    \n",
    "    return A\n",
    "\n",
    "\n",
    "def least_squares_est(A, b):\n",
    "    \n",
    "    y = np.linalg.inv(A.transpose((0,2,1)) @ A) @ (A.transpose((0,2,1)) @ b[:, :, None])\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def camera_image_center_pairs(P1, P2):\n",
    "    # Calculate Camera Centers\n",
    "    R1, T1 = P1[:, 0:3], P1[:,3]\n",
    "    R2, T2 = P2[:, 0:3], P2[:,3]\n",
    "\n",
    "    # Camera center of the first camera\n",
    "    C1 = np.linalg.inv(R1) @ (-T1)\n",
    "    C2 = np.linalg.inv(R2) @ (-T2)\n",
    "\n",
    "    # Image Plane coordinate\n",
    "    I1 = np.linalg.inv(R1) @ (-(np.array([0,0,-1]) + T1.reshape((3,)))*np.array([1,1,-1]))\n",
    "    I2 = np.linalg.inv(R2) @ (-(np.array([0,0,-1]) + T2.reshape((3,)))*np.array([1,1,-1]))\n",
    "\n",
    "    C = np.vstack([C1,C2])\n",
    "    I = np.vstack([I1,I2])\n",
    "    \n",
    "    return C, I\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Triangulation Sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_triangulation(params, bounding_box_size, threshold, num_feature_points = None, order = None, image_list = None):\n",
    "    X_list = []\n",
    "    C_list = []\n",
    "    I_list = []\n",
    "    #len(dino_params)\n",
    "    for i in range(len(params)-1):\n",
    "        print(f\"Comparing Images {order[i]} and {order[i+1]}\")\n",
    "        # Calculate the Fundimental Matrix\n",
    "#         C1_params = dino_params[i]\n",
    "#         C2_params = dino_params[i+1]\n",
    "        C1_params = params[order[i]]\n",
    "        C2_params = params[order[i+1]]\n",
    "\n",
    "\n",
    "        K1, R1, T1 = C1_params\n",
    "        K2, R2, T2 = C2_params\n",
    "\n",
    "        F = get_F_matrix_sourishghosh(K1, R1, T1, K2, R2, T2)\n",
    "\n",
    "        # Get images\n",
    "        imL = image_list[order[i]]\n",
    "        imR = image_list[order[i+1]]\n",
    "        h,w,c = np.shape(imL)\n",
    "\n",
    "        # ------------------------- Get Match Points from Edge Points ------------------------- #\n",
    "\n",
    "        # -- uncomment below for random points on dino\n",
    "        x1 = sample_on_dino(imL, num_feature_points, threshold)\n",
    "\n",
    "        mask_imL = np.where(np.sum(imL, axis = 2) > threshold, 1, 0)\n",
    "        #x1 = coords_subpix_cleaned\n",
    "\n",
    "        x2, u1_list, v1_list, u2_list, v2_list = \\\n",
    "            get_match_points_linspace(imL, imR, x1, F, bounding_box_size, epsilon = 0.1, threshold = 0.9)\n",
    "    \n",
    "        # ------------------------- Filter Edge Points ------------------------- #    \n",
    "\n",
    "        x2_filtered = x2[np.where(x2.sum(axis = 1) != -2)]\n",
    "        x1_filtered = x1[np.where(x2.sum(axis = 1) != -2)]\n",
    "\n",
    "        P1 = K1 @ np.hstack([R1, T1])\n",
    "        P2 = K2 @ np.hstack([R2, T2])\n",
    "        \n",
    "        if (x1_filtered.size == 0) or (x2_filtered.size == 0):\n",
    "            print(\"WARNING: no matches are good enough!\")\n",
    "        else:\n",
    "            X = triangulation(x1_filtered, x2_filtered, P1, P2)\n",
    "\n",
    "            C, I = camera_image_center_pairs(P1, P2)\n",
    "\n",
    "            X_list.append(X)\n",
    "            C_list.append(C)\n",
    "            I_list.append(I)\n",
    "\n",
    "    print('Done')\n",
    "    # Save parameters\n",
    "    with open('X_C_I_list_final.pkl', 'wb') as handle:\n",
    "        pkl.dump([X_list, C_list, I_list], handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return X_list, C_list, I_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_triangulated(X_list, C_list, I_list, scale = 0.05):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    if C_list == None and I_list == None:\n",
    "        for i in range(len(X_list)):\n",
    "\n",
    "            ax.scatter3D(X_list[i][:,0],X_list[i][:,1],X_list[i][:,2])\n",
    "            plt.show()\n",
    "\n",
    "        ax.set_xlim([-scale, scale])\n",
    "        ax.set_ylim([-scale, scale])\n",
    "        ax.set_zlim([-scale, scale])\n",
    "    else:\n",
    "        for i in range(len(X_list)):\n",
    "\n",
    "            ax.scatter3D(X_list[i][:,0],X_list[i][:,1],X_list[i][:,2])\n",
    "            ax.scatter3D(C_list[i][:,0],C_list[i][:,1],C_list[i][:,2], color = \"r\")#CAMERA CENTER\n",
    "            ax.scatter3D(I_list[i][:,0],I_list[i][:,1],I_list[i][:,2], color = \"g\")#IMAGE CENTER    \n",
    "            plt.show()\n",
    "\n",
    "        ax.set_xlim([-scale, scale])\n",
    "        ax.set_ylim([-scale, scale])\n",
    "        ax.set_zlim([-scale, scale])\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 46 imgs --> 24 min for 1000 num_feature_points\n",
    "# 363 imgs --> 1.5h for 500 num_feature_points (probably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DI = Dino_Images(input_dic_path=\"dino\", par_path = \"/dino_par.txt\")\n",
    "\n",
    "dino_params = DI.params\n",
    "image_list_dino = DI.image_list\n",
    "order_list_dino = np.arange(len(dino_params)).tolist()\n",
    "\n",
    "# image_list = image_list_dino#[144:146]\n",
    "# order_list = order_list_dino#[144:146]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_list = image_list_dino[144:146]\n",
    "# order_list = order_list_dino[144:146]\n",
    "\n",
    "# X = sample_on_dino(image_list[0], 100)\n",
    "# plt.imshow(image_list[0])\n",
    "# plt.scatter(X[:,0], X[:,1])\n",
    "\n",
    "# C1, C2 = dino_params.get(1), dino_params.get(2)\n",
    "# F = get_F_matrix_sourishghosh(*C1, *C2)\n",
    "\n",
    "# h,w,c = np.shape(image_list[0])\n",
    "# u = np.linspace(0, w, num = 5*w)\n",
    "\n",
    "# u2_list, v2_list, l2_list = get_right_epipolar_line(image_list[1], X, F)\n",
    "\n",
    "# start, start_line = point_and_line(0, X, w, h, u, l2_list)\n",
    "# end, end_line = point_and_line(-1, X, w, h, u, l2_list)\n",
    "\n",
    "# u2, v2 = np.arange(1, 10), np.arange(11, 20)\n",
    "# np.vstack([u2, v2]).T\n",
    "\n",
    "# matched_start, score_start = get_right_image_point_cv(image_list[0], image_list[1], start, start_line, shift = (-20, 20), bbr = 15, epsilon = 0.1, show_img = False)\n",
    "\n",
    "# x2, u1_list, v1_list, u2_list, v2_list \\\n",
    "# = get_match_points_linspace(image_list[0], image_list[1], X, F, bounding_box_size = 15, epsilon = 0.1, threshold = 0.8, delta = 0.00000000001)\n",
    "\n",
    "# plt.imshow(image_list[1])\n",
    "# plt.scatter(x2[:,0], x2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bounding_box_size = 15\n",
    "dino_threshold = 0.4\n",
    "num_feature_points = 2\n",
    "\n",
    "X_list, C_list, I_list = sequential_triangulation(dino_params, \n",
    "                                                  bounding_box_size,\n",
    "                                                  dino_threshold, \n",
    "                                                  num_feature_points = num_feature_points,\n",
    "                                                  order = order_list,\n",
    "                                                  image_list = image_list\n",
    "#                                                  order = DI.sequential_image_order,\n",
    "#                                                  image_list = DI.image_list\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_all_triangulated(X_list, C_list = None, I_list = None, scale = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(image_list[144])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_list[145])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f63f26de748f105537615ec22abe0c9c589e2c8df9dc8e7c73b924db79e12be"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
