{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangulation for sequence of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.image as image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image\n",
    "from Dino_Images import *\n",
    "from skimage import feature\n",
    "from skimage.feature import (corner_harris, corner_peaks, plot_matches, BRIEF, match_descriptors)\n",
    "from skimage.transform import warp, FundamentalMatrixTransform, rotate\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import ransac\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating F matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(dino_param_df):\n",
    "    \"\"\"\n",
    "    Read the text file to get the parmeters of interest: K, R, T\n",
    "    \"\"\"\n",
    "\n",
    "    param_dict = {}\n",
    "\n",
    "    for i in range(len(dino_param_df)):\n",
    "        row = dino_param_df.loc[i]\n",
    "        K = np.array(row.loc[1:9].tolist()).reshape(3,3)\n",
    "        R = np.array(row.loc[10:18].tolist()).reshape(3,3)\n",
    "        T = np.array(row.loc[19:].tolist()).reshape(3,1)\n",
    "\n",
    "        # param_dict[dino_param_df.loc[i][0]] = [K, R, T]\n",
    "        param_dict[i] = [K, R, T]\n",
    "    \n",
    "    return param_dict\n",
    "\n",
    "\n",
    "def get_cross_matrix(T):\n",
    "    \"\"\"\n",
    "    T_mat = [ 0  -a3 a2]\n",
    "            [ a3  0 -a1]\n",
    "            [-a2 a1  0 ]\n",
    "    \"\"\"\n",
    "    a1, a2, a3 = T\n",
    "\n",
    "    T_mat = np.zeros((3,3))\n",
    "    T_mat[0, 1] = -a3\n",
    "    T_mat[0, 2] = a2\n",
    "    T_mat[1, 0] = a3\n",
    "    T_mat[1, 2] = -a1\n",
    "    T_mat[2, 0] = -a2\n",
    "    T_mat[2, 1] = a1\n",
    "\n",
    "    return T_mat\n",
    "\n",
    "def get_F_matrix_sourishghosh(K1, R1, T1, K2, R2, T2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    P1 = K1 @ np.hstack([R1, T1])\n",
    "    P2 = K2 @ np.hstack([R2, T2])\n",
    "\n",
    "    # Calculate Pseudo-Inverse\n",
    "    P1_pI = np.linalg.pinv(P1)\n",
    "    \n",
    "    # Camera center of the first camera\n",
    "    C1 = np.linalg.solve(P1[:, :-1], -P1[:, -1])\n",
    "    \n",
    "    # Camera center in homogenous coordinates\n",
    "    C1 = np.hstack([C1, 1])\n",
    "    \n",
    "    # Epipole of C1 into second image\n",
    "    E2 = P2 @ C1\n",
    "\n",
    "    # Calculate F matrix\n",
    "    E2_mat = get_cross_matrix(E2)\n",
    "    F_mat = E2_mat @ P2 @ P1_pI\n",
    "\n",
    "    return F_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Matching Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_on_dino(imL, num_feature_points = None, dino_threshold = 0.4):\n",
    "    \"\"\"\n",
    "    bounding_box_size must be ODD number\n",
    "    \"\"\"\n",
    "\n",
    "    # SAMPLE RANDOM INDICES\n",
    "    h,w,_ = np.shape(imL)\n",
    "\n",
    "    mask_dino = np.where(np.sum(imL, axis = 2) > dino_threshold, 1, 0)\n",
    "    mask_dino = np.where(mask_dino == 1)\n",
    "\n",
    "    points = np.array([mask_dino[1], mask_dino[0]]).T\n",
    "    \n",
    "    if not num_feature_points:\n",
    "        return points\n",
    "    \n",
    "    idx = np.random.choice(np.arange(points.shape[0]), size = num_feature_points, replace = False)\n",
    "\n",
    "    x1 = points[idx]\n",
    "    \n",
    "    return x1\n",
    "\n",
    "\n",
    "def get_bound_box_intensities(im, point, bounding_box_size):\n",
    "    u, v_dec = int(point[0]), point[1]\n",
    "    v_ceil, v_floor = int(np.ceil(v_dec)), int(np.floor(v_dec))\n",
    "\n",
    "    i = bounding_box_size//2\n",
    "\n",
    "    im_cropped_list = []\n",
    "\n",
    "    for v in [v_ceil, v_floor]:\n",
    "        w_min, w_max = u - i, u + i\n",
    "        h_min, h_max = v - i, v + i\n",
    "\n",
    "        im_cropped_list.append(im[h_min:(h_max+1), w_min:(w_max+1), :])\n",
    "\n",
    "    return im_cropped_list[0], v_ceil, im_cropped_list[1], v_floor\n",
    "\n",
    "\n",
    "def loss_function_abs(image_point, image_point_2, imL_cropped, imR_cropped): # Depreciated\n",
    "\n",
    "    # Photoconsistency (?) + (Positional Consistency)\n",
    "    # Photoconsistency hovers around [0.1, 12]\n",
    "    # Positional Consistency hovers around [30, 600] (divide by 100 maybe?)\n",
    "    loss = 70*np.sum(np.abs(imL_cropped - imR_cropped)) + np.sum(np.linalg.norm(image_point - image_point_2))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_function_default(image_point, image_point_2, imL_cropped, imR_cropped):\n",
    "\n",
    "    # Photoconsistency (?) + (Positional Consistency)\n",
    "    photo_con_loss = np.sum(np.abs(imL_cropped - imR_cropped))\n",
    "    pos_loss = np.sum(np.abs(image_point[1] - image_point_2[1]))\n",
    "\n",
    "    loss = photo_con_loss + 3*pos_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_right_epipolar_line(imR, x1, F):\n",
    "    \"\"\"\n",
    "    x1 are image points\n",
    "    \"\"\"\n",
    "\n",
    "    def predict_y(l, x): \n",
    "        a = -np.divide(l[:,0], l[:,1]) \n",
    "        b = -np.divide(l[:,2], l[:,1]) \n",
    "\n",
    "        return np.multiply(a[:,None], x) + b[:,None] \n",
    "\n",
    "    x1_homo = np.append(x1, np.ones(len(x1))[:,None], axis = 1) \n",
    "    \n",
    "    l2 = x1_homo @ F.T\n",
    "\n",
    "    u = np.repeat(np.array([0, imR.shape[1]])[None,:], len(x1), axis=0) \n",
    "\n",
    "    v = predict_y(l2, u)\n",
    "\n",
    "    return u, v, l2\n",
    "\n",
    "\n",
    "def get_left_epipolar_line(imL, x2, F):\n",
    "    \"\"\"\n",
    "    x1 are image points\n",
    "    \"\"\"\n",
    "\n",
    "    def predict_y(l, x): \n",
    "        a = -np.divide(l[:,0], l[:,1]) \n",
    "        b = -np.divide(l[:,2], l[:,1]) \n",
    "\n",
    "        return np.multiply(a[:,None], x) + b[:,None] \n",
    "    \n",
    "    x2_homo = np.append(x2, np.ones(len(x2))[:,None], axis = 1) \n",
    "    \n",
    "    l1 = x2_homo @ F\n",
    "\n",
    "    u = np.repeat(np.array([0, imL.shape[1]])[None,:], len(x2), axis=0) \n",
    "\n",
    "    v = predict_y(l1, u)\n",
    "\n",
    "    return u, v, l1\n",
    "\n",
    "def get_right_image_point(imL, imR, image_point, x2_on_eline, \n",
    "                               bounding_box_size, loss_function = loss_function_default):\n",
    "    \n",
    "    final_image_point_2_list, final_loss_list = [], []\n",
    "    \n",
    "    # For giving image_point and bounding_box_size return cropped array\n",
    "    imL_cropped, _, _, _ = get_bound_box_intensities(imL, image_point, bounding_box_size)\n",
    "\n",
    "    for i in range(len(x2_on_eline)):\n",
    "        # Testing if current point on epipolar line in image 2 works\n",
    "        image_point_2 = x2_on_eline[i, :]\n",
    "        \n",
    "        # Return the (bounding_box_size x bounding_box_size x 3)\n",
    "        imR_cropped_ceil, v_ceil, imR_cropped_floor, v_floor = \\\n",
    "        get_bound_box_intensities(imR, image_point_2, bounding_box_size)\n",
    "\n",
    "        # Custom loss functino\n",
    "        image_point_2_list= [np.array([image_point_2[0], v_ceil]), np.array([image_point_2[0], v_floor])]\n",
    "        \n",
    "        # bb_int_L[0] = bb_int_L[1] since the image_point are all ints to begin with\n",
    "        loss_list = [loss_function(image_point, image_point_2_list[0], imL_cropped, imR_cropped_ceil), \\\n",
    "                        loss_function(image_point, image_point_2_list[1], imL_cropped, imR_cropped_floor)]\n",
    "\n",
    "        loss_arg = np.argmin(loss_list)\n",
    "        \n",
    "        image_point_2 = image_point_2_list[loss_arg]\n",
    "        loss = loss_list[loss_arg]\n",
    "        \n",
    "        final_image_point_2_list.append(image_point_2)\n",
    "        final_loss_list.append(loss)\n",
    "    \n",
    "    final_R_point = final_image_point_2_list[np.argmin(final_loss_list)]\n",
    "\n",
    "    return final_R_point\n",
    "\n",
    "def point_and_line(point_index, x1, w, h, u, l2_list):\n",
    "    '''\n",
    "    Takes a index in x1 and returns the point along with its corresponding epipolar line formatted nicely as input\n",
    "    for the matching function \n",
    "    '''\n",
    "    image_point = np.array([x1[point_index, 0], x1[point_index, 1]])\n",
    "\n",
    "    # l2 corresponding with the image_point\n",
    "    l2 = l2_list[point_index,:]\n",
    "\n",
    "    # Generate all points on epipolar line projected from first image plane\n",
    "    a = -l2[0]/l2[1]\n",
    "    b = -l2[2]/l2[1]\n",
    "\n",
    "    # Produce all the points on the epipolar line\n",
    "#     u2 = np.linspace(0, w, num = 5*w)\n",
    "#    v2 = a*u+b\n",
    "\n",
    "    v_top = 0\n",
    "    u_top = -b/a\n",
    "    \n",
    "    v_bot = h\n",
    "    u_bot = (h-b)/a\n",
    "    \n",
    "#     delta_v = v_bot - v_top\n",
    "#     delta_u = u_bot - u_top\n",
    "    \n",
    "    u2 = np.linspace(u_top, u_bot, min([w,h]))\n",
    "    v2 = np.linspace(v_top, v_bot, min([w,h]))\n",
    "\n",
    "    # Extract all the points on the epipolar line that are within the image (and not restricted by the bounding_box_size)\n",
    "    idx = np.where((v2 > bounding_box_size)&(v2 < h-bounding_box_size)& \\\n",
    "    (u2 > bounding_box_size)&(u2 < w-bounding_box_size))[0]\n",
    "\n",
    "    u2 = u2[idx]\n",
    "    v2 = v2[idx]\n",
    "    \n",
    "    # Stack the individual coordinates to make (n x 2) vector\n",
    "    x2_on_eline = np.vstack((u2, v2)).T\n",
    "    x2_on_eline = np.rint(x2_on_eline).astype(int)\n",
    "    image_point = np.rint(image_point).astype(int)\n",
    "\n",
    "    return image_point, x2_on_eline\n",
    "\n",
    "def get_right_image_point_cv(imL, imR, impts, x2_on_eline = None, shift = None,\n",
    "                               bbr = 5, epsilon = 0, method = cv2.TM_CCOEFF_NORMED,\n",
    "                               show_img = False, matched_start = None, matched_end = None, delta = 0):\n",
    "    # delta = 0.00000000001 DEFAULT FOR dinoRing and dinoSparseRing\n",
    "    h, w = bbr*2+1, bbr*2+1\n",
    "    x, y = impts\n",
    "    img = imR.copy()\n",
    "    img_ref = imL.copy()\n",
    "    if not shift: # Define horizontal shift\n",
    "        shift = (-bbr, bbr)\n",
    "        \n",
    "    # Get template from imL\n",
    "    imL_padded = np.pad(imL, [(bbr, bbr), (bbr, bbr), (0, 0)], mode='constant')\n",
    "    template = imL_padded[y:y+h, x:x+w, :]\n",
    "\n",
    "    result = cv2.matchTemplate(img, template, method)\n",
    "    result_padded = np.pad(result, [(bbr, bbr), (bbr, bbr)], mode='constant')\n",
    "\n",
    "    # return location with max score along x2 lines\n",
    "    shift_template = np.repeat(np.array([0, 1])[None, :], x2_on_eline.shape[0], axis = 0)\n",
    "    shift_diff = shift[1] - shift[0] + 1\n",
    "    result_eline = np.zeros((shift_diff, x2_on_eline.shape[0]))\n",
    "\n",
    "    # used to compute the projection of the point to be matched along the line from the\n",
    "    # match of the start to the match of the end in the right image\n",
    "    if not(matched_start is None and matched_end is None):\n",
    "        line = matched_start - matched_end\n",
    "        l = 1 / np.sum((line)**2) * (line)\n",
    "    \n",
    "    for s in range(shift[0], shift[1]):\n",
    "        x2_eline_shifted = x2_on_eline + shift_template * s\n",
    "        x2_eline_shifted = np.where(x2_eline_shifted < 0, 0, x2_eline_shifted)\n",
    "        x2_eline_shifted_y = np.where(x2_eline_shifted[:,1] >= img.shape[0], img.shape[0] - 1, x2_eline_shifted[:,1])\n",
    "        x2_eline_shifted_x = np.where(x2_eline_shifted[:,0] >= img.shape[1], img.shape[1] - 1, x2_eline_shifted[:,0])\n",
    "        result_eline_shifted = result_padded[(x2_eline_shifted_y, x2_eline_shifted_x)]\n",
    "        # Add penality on shifting\n",
    "        result_eline_shifted -= epsilon * result_eline_shifted * abs(2 * s) / shift_diff \n",
    "        \n",
    "        # Add penality on dist from line between matched_start and matched_end to enforce order\n",
    "        if not(matched_start is None and matched_end is None):\n",
    "            \n",
    "            # reshaping the points on the epipolar line so we can calculate all the projections at once\n",
    "            epi_line = np.array([x2_eline_shifted_y, x2_eline_shifted_x])\n",
    "            \n",
    "            # create copies of the sampled line so we can take multiple dot products simultaneously\n",
    "            line_reshaped = np.tile(line, epi_line.shape[1]).reshape((epi_line.shape[1], epi_line.shape[0]))\n",
    "            \n",
    "            a, b = epi_line.shape\n",
    "            matched_start_reshaped = np.tile(matched_start, epi_line.shape[1]).reshape(epi_line.shape)\n",
    "            \n",
    "            dot_product = np.dot(epi_line.transpose(), line_reshaped.transpose())\n",
    "            scale = np.sum(dot_product, axis=1)\n",
    "            projections = matched_start_reshaped + np.multiply(scale, np.tile(l, epi_line.shape[1]).reshape((a,b)))\n",
    "            \n",
    "            diff = projections - epi_line\n",
    "            penalty = np.sum(np.square(diff),axis=0)\n",
    "\n",
    "            result_eline_shifted -= delta * penalty \n",
    "        \n",
    "        result_eline[s - shift[0], :] = result_eline_shifted\n",
    "\n",
    "    score = result_eline.max()\n",
    "    max_idx = np.where(result_eline == score)\n",
    "    location_eline = x2_on_eline + shift_template * (max_idx[0][0] + shift[0])\n",
    "    location = location_eline[max_idx[1][0],:]\n",
    "    \n",
    "    if show_img:\n",
    "        bottom_right = (location[0] + w, location[1] + h)   \n",
    "        impts_bottom_right = (x + w, y + h)   \n",
    "        cv2.rectangle(img, location, bottom_right, 255, 5)\n",
    "        cv2.rectangle(img_ref, impts, impts_bottom_right, 255, 5)\n",
    "\n",
    "        plt.figure(0,figsize = (10, 4))\n",
    "        ax81 = plt.subplot(121)\n",
    "        plt.imshow(img_ref)\n",
    "        ax82 = plt.subplot(122)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "    return location, score\n",
    "\n",
    "def get_match_points_linspace(imL, imR, x1, F, bounding_box_size, epsilon, threshold = 0.8, delta = 0.00000000001):\n",
    "\n",
    "    # Define some common variables:\n",
    "        # after rotating img:(480 x 640 x 3)\n",
    "    h,w,c = np.shape(imL)\n",
    "    u = np.linspace(0, w, num = 5*w)\n",
    "\n",
    "    u2_list, v2_list, l2_list = get_right_epipolar_line(imR, x1, F)\n",
    "\n",
    "    \n",
    "    start, start_line = point_and_line(0, x1, w, h, u, l2_list)\n",
    "    end, end_line = point_and_line(-1, x1, w, h, u, l2_list)\n",
    "    \n",
    "    matched_start, score_start = get_right_image_point_cv(imL, imR, start, start_line, shift = (-20, 20), bbr = bounding_box_size, epsilon = epsilon, show_img = False)\n",
    "    matched_end, score_end = get_right_image_point_cv(imL, imR, end, end_line, shift = (-20, 20), bbr = bounding_box_size, epsilon = epsilon, show_img = False)\n",
    "\n",
    "    x2_list = []\n",
    "    for i in range(len(x1)):\n",
    "        image_point, x2_on_eline = point_and_line(i, x1, w, h, u, l2_list)\n",
    "\n",
    "    #         # Return final_R_point on the right image that is closest to image_point on the left image \n",
    "        final_R_point, score = get_right_image_point_cv(imL, imR, image_point, x2_on_eline, shift = (-20, 20), \n",
    "                                                   bbr = bounding_box_size, epsilon = epsilon, matched_start = matched_start, matched_end = matched_end, delta=delta)\n",
    "\n",
    "        x2_list.append(final_R_point if score > threshold else np.array([-1,-1])) \n",
    "\n",
    "    x2 = np.array(x2_list)\n",
    "    \n",
    "    u1_list, v1_list, _ = get_left_epipolar_line(imL, x2, F)\n",
    "\n",
    "    return x2, u1_list, v1_list, u2_list, v2_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulation(x1, x2, P1, P2):\n",
    "    A = np.apply_along_axis(get_matrix_A, 1, np.hstack([x1, x2]), P1, P2)\n",
    "\n",
    "    # least squares for solving linear system A_{0:2} X_{0:2} = - A_3 \n",
    "    A_02 = A[:, :, 0:3]       # the first 3 columns of 4x4 matrix A\n",
    "    A_3  = A[:, :, 3]       # the last column on 4x4 matrix A\n",
    "\n",
    "    X = least_squares_est(A_02, -A_3)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def get_matrix_A(pair_points, P_1, P_2):\n",
    "    # X = np.append([n_ptsL, n_ptsR])\n",
    "    A_row_1 = P_1[0, :] - pair_points[0]*P_1[2, :]\n",
    "    A_row_2 = P_1[1, :] - pair_points[1]*P_1[2, :]\n",
    "    A_row_3 = P_2[0, :] - pair_points[2]*P_2[2, :]\n",
    "    A_row_4 = P_2[1, :] - pair_points[3]*P_2[2, :]\n",
    "    \n",
    "    A = np.vstack([A_row_1, A_row_2, A_row_3, A_row_4])\n",
    "    \n",
    "    return A\n",
    "\n",
    "\n",
    "def least_squares_est(A, b):\n",
    "    \n",
    "    y = np.linalg.inv(A.transpose((0,2,1)) @ A) @ (A.transpose((0,2,1)) @ b[:, :, None])\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def camera_image_center_pairs(P1, P2):\n",
    "    # Calculate Camera Centers\n",
    "    R1, T1 = P1[:, 0:3], P1[:,3]\n",
    "    R2, T2 = P2[:, 0:3], P2[:,3]\n",
    "\n",
    "    # Camera center of the first camera\n",
    "    C1 = np.linalg.inv(R1) @ (-T1)\n",
    "    C2 = np.linalg.inv(R2) @ (-T2)\n",
    "\n",
    "    # Image Plane coordinate\n",
    "    I1 = np.linalg.inv(R1) @ (-(np.array([0,0,-1]) + T1.reshape((3,)))*np.array([1,1,-1]))\n",
    "    I2 = np.linalg.inv(R2) @ (-(np.array([0,0,-1]) + T2.reshape((3,)))*np.array([1,1,-1]))\n",
    "\n",
    "    C = np.vstack([C1,C2])\n",
    "    I = np.vstack([I1,I2])\n",
    "    \n",
    "    return C, I\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Triangulation Sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_triangulation(params, bounding_box_size, threshold, num_feature_points = None, order = None, image_list = None):\n",
    "    X_list = []\n",
    "    C_list = []\n",
    "    I_list = []\n",
    "    #len(dino_params)\n",
    "    for i in range(len(params)-1):\n",
    "        print(f\"Comparing Images {order[i]} and {order[i+1]}\")\n",
    "        # Calculate the Fundimental Matrix\n",
    "#         C1_params = dino_params[i]\n",
    "#         C2_params = dino_params[i+1]\n",
    "        C1_params = params[order[i]]\n",
    "        C2_params = params[order[i+1]]\n",
    "\n",
    "\n",
    "        K1, R1, T1 = C1_params\n",
    "        K2, R2, T2 = C2_params\n",
    "\n",
    "        F = get_F_matrix_sourishghosh(K1, R1, T1, K2, R2, T2)\n",
    "\n",
    "        # Get images\n",
    "        imL = image_list[order[i]]\n",
    "        imR = image_list[order[i+1]]\n",
    "        h,w,c = np.shape(imL)\n",
    "\n",
    "        # ------------------------- Get Match Points from Edge Points ------------------------- #\n",
    "\n",
    "        # -- uncomment below for random points on dino\n",
    "        x1 = sample_on_dino(imL, num_feature_points, threshold)\n",
    "\n",
    "        mask_imL = np.where(np.sum(imL, axis = 2) > threshold, 1, 0)\n",
    "        #x1 = coords_subpix_cleaned\n",
    "\n",
    "        x2, u1_list, v1_list, u2_list, v2_list = \\\n",
    "            get_match_points_linspace(imL, imR, x1, F, bounding_box_size, epsilon = 0.1, threshold = 0.9)\n",
    "    \n",
    "        # ------------------------- Filter Edge Points ------------------------- #    \n",
    "\n",
    "        x2_filtered = x2[np.where(x2.sum(axis = 1) != -2)]\n",
    "        x1_filtered = x1[np.where(x2.sum(axis = 1) != -2)]\n",
    "\n",
    "        P1 = K1 @ np.hstack([R1, T1])\n",
    "        P2 = K2 @ np.hstack([R2, T2])\n",
    "        \n",
    "        if (x1_filtered.size == 0) or (x2_filtered.size == 0):\n",
    "            print(\"WARNING: no matches are good enough!\")\n",
    "        else:\n",
    "            X = triangulation(x1_filtered, x2_filtered, P1, P2)\n",
    "\n",
    "            C, I = camera_image_center_pairs(P1, P2)\n",
    "\n",
    "            X_list.append(X)\n",
    "            C_list.append(C)\n",
    "            I_list.append(I)\n",
    "\n",
    "    print('Done')\n",
    "    # Save parameters\n",
    "    with open('X_C_I_list_final.pkl', 'wb') as handle:\n",
    "        pkl.dump([X_list, C_list, I_list], handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return X_list, C_list, I_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_triangulated(X_list, C_list, I_list, scale = 0.05):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    if C_list == None and I_list == None:\n",
    "        for i in range(len(X_list)):\n",
    "\n",
    "            ax.scatter3D(X_list[i][:,0],X_list[i][:,1],X_list[i][:,2])\n",
    "            plt.show()\n",
    "\n",
    "        ax.set_xlim([-scale, scale])\n",
    "        ax.set_ylim([-scale, scale])\n",
    "        ax.set_zlim([-scale, scale])\n",
    "    else:\n",
    "        for i in range(len(X_list)):\n",
    "\n",
    "            ax.scatter3D(X_list[i][:,0],X_list[i][:,1],X_list[i][:,2])\n",
    "            ax.scatter3D(C_list[i][:,0],C_list[i][:,1],C_list[i][:,2], color = \"r\")#CAMERA CENTER\n",
    "            ax.scatter3D(I_list[i][:,0],I_list[i][:,1],I_list[i][:,2], color = \"g\")#IMAGE CENTER    \n",
    "            plt.show()\n",
    "\n",
    "        ax.set_xlim([-scale, scale])\n",
    "        ax.set_ylim([-scale, scale])\n",
    "        ax.set_zlim([-scale, scale])\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 46 imgs --> 24 min for 1000 num_feature_points\n",
    "# 363 imgs --> 1.5h for 500 num_feature_points (probably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DI = Dino_Images(input_dic_path=\"dino\", par_path = \"/dino_par.txt\")\n",
    "\n",
    "dino_params = DI.params\n",
    "image_list_dino = DI.image_list\n",
    "order_list_dino = np.arange(len(dino_params)).tolist()\n",
    "\n",
    "image_list = image_list_dino#[144:146]\n",
    "order_list = order_list_dino#[144:146]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_list = image_list_dino[144:146]\n",
    "# order_list = order_list_dino[144:146]\n",
    "\n",
    "# X = sample_on_dino(image_list[0], 100)\n",
    "# plt.imshow(image_list[0])\n",
    "# plt.scatter(X[:,0], X[:,1])\n",
    "\n",
    "# C1, C2 = dino_params.get(1), dino_params.get(2)\n",
    "# F = get_F_matrix_sourishghosh(*C1, *C2)\n",
    "\n",
    "# h,w,c = np.shape(image_list[0])\n",
    "# u = np.linspace(0, w, num = 5*w)\n",
    "\n",
    "# u2_list, v2_list, l2_list = get_right_epipolar_line(image_list[1], X, F)\n",
    "\n",
    "# start, start_line = point_and_line(0, X, w, h, u, l2_list)\n",
    "# end, end_line = point_and_line(-1, X, w, h, u, l2_list)\n",
    "\n",
    "# u2, v2 = np.arange(1, 10), np.arange(11, 20)\n",
    "# np.vstack([u2, v2]).T\n",
    "\n",
    "# matched_start, score_start = get_right_image_point_cv(image_list[0], image_list[1], start, start_line, shift = (-20, 20), bbr = 15, epsilon = 0.1, show_img = False)\n",
    "\n",
    "# x2, u1_list, v1_list, u2_list, v2_list \\\n",
    "# = get_match_points_linspace(image_list[0], image_list[1], X, F, bounding_box_size = 15, epsilon = 0.1, threshold = 0.8, delta = 0.00000000001)\n",
    "\n",
    "# plt.imshow(image_list[1])\n",
    "# plt.scatter(x2[:,0], x2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Images 0 and 1\n",
      "Comparing Images 1 and 2\n",
      "Comparing Images 2 and 3\n",
      "Comparing Images 3 and 4\n",
      "Comparing Images 4 and 5\n",
      "Comparing Images 5 and 6\n",
      "Comparing Images 6 and 7\n",
      "Comparing Images 7 and 8\n",
      "Comparing Images 8 and 9\n",
      "Comparing Images 9 and 10\n",
      "Comparing Images 10 and 11\n",
      "Comparing Images 11 and 12\n",
      "Comparing Images 12 and 13\n",
      "Comparing Images 13 and 14\n",
      "Comparing Images 14 and 15\n",
      "Comparing Images 15 and 16\n",
      "Comparing Images 16 and 17\n",
      "Comparing Images 17 and 18\n",
      "Comparing Images 18 and 19\n",
      "Comparing Images 19 and 20\n",
      "Comparing Images 20 and 21\n",
      "Comparing Images 21 and 22\n",
      "Comparing Images 22 and 23\n",
      "Comparing Images 23 and 24\n",
      "Comparing Images 24 and 25\n",
      "Comparing Images 25 and 26\n",
      "Comparing Images 26 and 27\n",
      "Comparing Images 27 and 28\n",
      "Comparing Images 28 and 29\n",
      "Comparing Images 29 and 30\n",
      "Comparing Images 30 and 31\n",
      "Comparing Images 31 and 32\n",
      "Comparing Images 32 and 33\n",
      "Comparing Images 33 and 34\n",
      "Comparing Images 34 and 35\n",
      "Comparing Images 35 and 36\n",
      "Comparing Images 36 and 37\n",
      "Comparing Images 37 and 38\n",
      "Comparing Images 38 and 39\n",
      "Comparing Images 39 and 40\n",
      "Comparing Images 40 and 41\n",
      "Comparing Images 41 and 42\n",
      "Comparing Images 42 and 43\n",
      "Comparing Images 43 and 44\n",
      "Comparing Images 44 and 45\n",
      "Comparing Images 45 and 46\n",
      "Comparing Images 46 and 47\n",
      "Comparing Images 47 and 48\n",
      "Comparing Images 48 and 49\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f7/7wm8ypsx1_zcy_df6_f5nrl40000gn/T/ipykernel_58781/3126680712.py\u001b[0m in \u001b[0;36msequential_triangulation\u001b[0;34m(params, bounding_box_size, threshold, num_feature_points, order, image_list)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu1_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu2_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2_list\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mget_match_points_linspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounding_box_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# ------------------------- Filter Edge Points ------------------------- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f7/7wm8ypsx1_zcy_df6_f5nrl40000gn/T/ipykernel_58781/529450753.py\u001b[0m in \u001b[0;36mget_match_points_linspace\u001b[0;34m(imL, imR, x1, F, bounding_box_size, epsilon, threshold, delta)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;31m#         # Return final_R_point on the right image that is closest to image_point on the left image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         final_R_point, score = get_right_image_point_cv(imL, imR, image_point, x2_on_eline, shift = (-20, 20), \n\u001b[0m\u001b[1;32m    285\u001b[0m                                                    bbr = bounding_box_size, epsilon = epsilon, matched_start = matched_start, matched_end = matched_end, delta=delta)\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f7/7wm8ypsx1_zcy_df6_f5nrl40000gn/T/ipykernel_58781/529450753.py\u001b[0m in \u001b[0;36mget_right_image_point_cv\u001b[0;34m(imL, imR, impts, x2_on_eline, shift, bbr, epsilon, method, show_img, matched_start, matched_end, delta)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mresult_eline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_eline_shifted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_eline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0mmax_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_eline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mlocation_eline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2_on_eline\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshift_template\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     37\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     38\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bounding_box_size = 15\n",
    "dino_threshold = 0.4\n",
    "num_feature_points = 1000\n",
    "\n",
    "X_list, C_list, I_list = sequential_triangulation(dino_params, \n",
    "                                                  bounding_box_size,\n",
    "                                                  dino_threshold, \n",
    "                                                  num_feature_points = num_feature_points,\n",
    "                                                  order = order_list,\n",
    "                                                  image_list = image_list\n",
    "#                                                  order = DI.sequential_image_order,\n",
    "#                                                  image_list = DI.image_list\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f7/7wm8ypsx1_zcy_df6_f5nrl40000gn/T/ipykernel_58781/1369074189.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'notebook'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_all_triangulated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_list' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "plot_all_triangulated(X_list, C_list = None, I_list = None, scale = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# plt.imshow(image_list[144])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(image_list[145])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f63f26de748f105537615ec22abe0c9c589e2c8df9dc8e7c73b924db79e12be"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
