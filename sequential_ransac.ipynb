{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Read fundamental matrix (F) from the csv file.\n",
    "\n",
    "1. Center data (choose any (or first one) to be the world center coordinate system)\n",
    "- subtract translation vector to everything\n",
    "- compute inverse of rotation matrix (then apply to every)\n",
    "\n",
    "2. Apply assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dino_Images import Dino_Images\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "DI = Dino_Images()\n",
    "\n",
    "num_images, image_path, \\\n",
    "               centered_calibration_matrices, centered_rotation_matrices, centered_translation_vectors = DI.parse_par(\"/dinoSR_par.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select normalized coordinates for matched features that are inliers for essential matrix E. \n",
    "n_ptsL_in = n_ptsL[ind[E_inliers]]\n",
    "n_ptsR_in = n_ptsR[ind[E_inliers]]\n",
    "# Form matrix A in equation AX=0 where X represent 4 vectors (homogeneous representation of 3D point).\n",
    "def get_matrix_A(pair_points, P_1, P_2):\n",
    "    # X = np.append([n_ptsL, n_ptsR])\n",
    "    A_row_1 = P_1[0, :] - pair_points[0]*P_1[2, :]\n",
    "    A_row_2 = P_1[1, :] - pair_points[1]*P_1[2, :]\n",
    "    A_row_3 = P_2[0, :] - pair_points[2]*P_2[2, :]\n",
    "    A_row_4 = P_2[1, :] - pair_points[3]*P_2[2, :]\n",
    "    \n",
    "    A = np.vstack([A_row_1, A_row_2, A_row_3, A_row_4])\n",
    "    \n",
    "    return A\n",
    "\n",
    "# Use your solution for Problem 6.\n",
    "# Each camera (projection matrix P) will define its own A  \n",
    "\n",
    "# HINT: to keep it simple, first solve the problem for one match.\n",
    "\n",
    "Aa = np.apply_along_axis(get_matrix_A, 1, np.hstack([n_ptsL_in, n_ptsR_in]), Pw, Pa)\n",
    "Ab = np.apply_along_axis(get_matrix_A, 1, np.hstack([n_ptsL_in, n_ptsR_in]), Pw, Pb)\n",
    "Ac = np.apply_along_axis(get_matrix_A, 1, np.hstack([n_ptsL_in, n_ptsR_in]), Pw, Pc)\n",
    "Ad = np.apply_along_axis(get_matrix_A, 1, np.hstack([n_ptsL_in, n_ptsR_in]), Pw, Pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib\n",
    "import matplotlib.image as image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import (corner_harris, corner_peaks, plot_matches, BRIEF, match_descriptors)\n",
    "from skimage.transform import warp, ProjectiveTransform, EssentialMatrixTransform, FundamentalMatrixTransform\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import ransac\n",
    "\n",
    "# Indicate (E) inlier matches in image 1 and image 2\n",
    "# loading two images (two camera views) and the corresponding matrix K (intrinsic parameters)\n",
    "imL = image.imread(\"images/kronan1.jpg\")\n",
    "imR = image.imread(\"images/kronan2.jpg\")\n",
    "imLgray = rgb2gray(imL)\n",
    "imRgray = rgb2gray(imR)\n",
    "\n",
    "K = 1.0e+03 * np.array([[2.3940, -0.0000,    0.9324],\n",
    "                        [     0,  2.3981,    0.6283],\n",
    "                        [     0,       0,    0.0010]])\n",
    "\n",
    "\n",
    "plt.figure(0,figsize = (10, 4))\n",
    "ax81 = plt.subplot(121)\n",
    "plt.imshow(imL)\n",
    "ax82 = plt.subplot(122)\n",
    "plt.imshow(imR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: corner_peaks and many other feature extraction functions return point coordinates as (y,x), that is (rows,cols)\n",
    "keypointsL = corner_peaks(corner_harris(imLgray), threshold_rel=0.001, min_distance=15)\n",
    "keypointsR = corner_peaks(corner_harris(imRgray), threshold_rel=0.001, min_distance=15)\n",
    "\n",
    "\n",
    "print ('the number of features in images 1 and 2 are {:5d} and {:5d}'.format(keypointsL.shape[0],keypointsR.shape[0]))\n",
    "\n",
    "fig = plt.figure(1,figsize = (10, 4))\n",
    "axA = plt.subplot(111)\n",
    "plt.gray()\n",
    "matchesLR = np.empty((0,2))\n",
    "plot_matches(axA, imL, imR, keypointsL, keypointsR, matchesLR)\n",
    "axA.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib\n",
    "import matplotlib.image as image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import (corner_harris, corner_peaks, plot_matches, BRIEF, match_descriptors)\n",
    "from skimage.transform import warp, ProjectiveTransform, EssentialMatrixTransform, FundamentalMatrixTransform\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import ransac\n",
    "\n",
    "# Indicate (E) inlier matches in image 1 and image 2\n",
    "# loading two images (two camera views) and the corresponding matrix K (intrinsic parameters)\n",
    "imL = image.imread(\"images/kronan1.jpg\")\n",
    "imR = image.imread(\"images/kronan2.jpg\")\n",
    "imLgray = rgb2gray(imL)\n",
    "imRgray = rgb2gray(imR)\n",
    "\n",
    "K = 1.0e+03 * np.array([[2.3940, -0.0000,    0.9324],\n",
    "                        [     0,  2.3981,    0.6283],\n",
    "                        [     0,       0,    0.0010]])\n",
    "\n",
    "\n",
    "plt.figure(0,figsize = (10, 4))\n",
    "ax81 = plt.subplot(121)\n",
    "plt.imshow(imL)\n",
    "ax82 = plt.subplot(122)\n",
    "plt.imshow(imR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = BRIEF()\n",
    "\n",
    "extractor.extract(imLgray, keypointsL)\n",
    "keypointsL = keypointsL[extractor.mask]         \n",
    "descriptorsL = extractor.descriptors\n",
    "\n",
    "extractor.extract(imRgray, keypointsR)\n",
    "keypointsR = keypointsR[extractor.mask]\n",
    "descriptorsR = extractor.descriptors\n",
    "\n",
    "matchesLR = match_descriptors(descriptorsL, descriptorsR, cross_check=True)\n",
    "\n",
    "print ('the number of matches is {:2d}'.format(matchesLR.shape[0]))\n",
    "\n",
    "fig = plt.figure(2,figsize = (10, 4))\n",
    "axA = plt.subplot(111)\n",
    "axA.set_title(\"matches\")\n",
    "plt.gray()\n",
    "plot_matches(axA, imL, imR, keypointsL, keypointsR, matchesLR) #, matches_color = 'r')\n",
    "axA.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1, len(num_images)):\n",
    "    \n",
    "    K = centered_calibration_matrices[i]]\n",
    "    R = centered_rotation_matrices[i]]\n",
    "    T = centered_translation_vectors[i]]\n",
    "    \n",
    "#     cross product matrix of T\n",
    "#     T_x = np.zeros((3,3):\n",
    "#     T_x[0] = ...\n",
    "                   \n",
    "    E = T_x @ R\n",
    "    Ue,Se,Ve = la.svd(E)\n",
    "    print (Se)\n",
    "    \n",
    "    # la.det(np.dot(Ue, Ve)) = 1 ==> switch sign of last col in Ve\n",
    "    Ve_1 = (Ve.T @ np.diag(np.array([1,1,-1]))).T\n",
    "\n",
    "    #Define W matrix\n",
    "    W = np.array([\n",
    "        [0, -1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    R1 = Ue @ W @ Ve_1\n",
    "    R2 = Ue @ W.T @ Ve_1\n",
    "    T1 = Ue[:, 2].reshape((3,1))\n",
    "    T2 = -Ue[:, 2].reshape((3,1))\n",
    "\n",
    "\n",
    "\n",
    "    # first camera matrix\n",
    "    Pw = np.hstack([np.identity(n=3), np.zeros(shape=(3,1))])\n",
    "\n",
    "    # four possible matrices for the second camera\n",
    "    Pa = np.hstack([R1, T1])\n",
    "    Pb = np.hstack([R1, T2])\n",
    "    Pc = np.hstack([R2, T1])\n",
    "    Pd = np.hstack([R2, T2])\n",
    "    \n",
    "\n",
    "\n",
    "    # la.det(np.dot(Ue, Ve)) = 1 ==> switch sign of last col in Ve\n",
    "    Ve_1 = (Ve.T @ np.diag(np.array([1,1,-1]))).T\n",
    "\n",
    "    #Define W matrix\n",
    "    W = np.array([\n",
    "        [0, -1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    R1 = Ue @ W @ Ve_1\n",
    "    R2 = Ue @ W.T @ Ve_1\n",
    "    T1 = Ue[:, 2].reshape((3,1))\n",
    "    T2 = -Ue[:, 2].reshape((3,1))\n",
    "\n",
    "\n",
    "\n",
    "    # first camera matrix\n",
    "    Pw = np.hstack([np.identity(n=3), np.zeros(shape=(3,1))])\n",
    "\n",
    "    # four possible matrices for the second camera\n",
    "    Pa = np.hstack([R1, T1])\n",
    "    Pb = np.hstack([R1, T2])\n",
    "    Pc = np.hstack([R2, T1])\n",
    "    Pd = np.hstack([R2, T2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
